<!doctype html>
<html lang="en">

<head>

    <title>Taehoon Kim (carpedm20)</title>

    <!-- meta -->
    <meta charset="utf-8" />
    <meta name="author" content="Taehoon Kim (김태훈)" />
    <meta content="Reinforcement Learning, Machine Learning" name="description">
    <meta name="keywords" content="Reinforcement Learning,Machine Learning,김태훈,강화 학습,머신러닝">
        <meta name="description" content="Sutton 교수님께서 70년간 AI 연구자들이 반복한 실수와 그로부터 우리가 배워야 하는 것에 대한 글 <The ..." />
    <meta name="dc.language" content="en" />
    <meta name="dc.license" content="">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta property="og:url" content="http://carpedm20.github.io"/>
    <meta property="og:image" content="http://carpedm20.github.io/images/carpedm20.png" />

    <!-- favicon -->
    <link rel="icon" href="/theme/favicon.ico" type="image/x-icon">

    <!-- newsfeeds -->
        <link href="https://carpedm20.github.io/feeds/all.atom.xml" type="application/atom+xml" rel="alternate" title="Taehoon Kim Full Atom Feed" />
        <link href="https://carpedm20.github.io/feeds/rss.xml" type="application/rss+xml" rel="alternate" title="Taehoon Kim RSS Feed" />
        <link href="https://carpedm20.github.io/feeds/blog.atom.xml" type="application/atom+xml" rel="alternate" title="Taehoon Kim Categories Atom Feed" />

    <!-- assets -->
    <!--[if lt IE 9]>
        <script src="https://html5shiv.googlecode.com/svn/trunk/html5.js"></script>
    <![endif]-->
    <link href="https://fonts.googleapis.com/css?family=Linden+Hill:400,400italic" rel="stylesheet" type="text/css">
    <link href="http://code.ionicframework.com/ionicons/2.0.1/css/ionicons.min.css" rel="stylesheet" type="text/css">
    <link href="https://carpedm20.github.io/theme/css/mfb.css" rel="stylesheet" type="text/css">
    <link rel="stylesheet" href="https://carpedm20.github.io/theme/css/main.css" type="text/css">
    <link rel="stylesheet" href="https://carpedm20.github.io/theme/css/pure.css" type="text/css">
    <link rel="stylesheet" href="https://carpedm20.github.io/theme/css/carpedm20.css" type="text/css">
    <link rel="stylesheet" href="https://carpedm20.github.io/theme/css/pygments.css" type="text/css">


</head>

<body>
    <div id="wrapper">
        <div id="blogtitle"><a href="https://carpedm20.github.io">Taehoon Kim</a></div>
        <ul id="mainnav">
            <li class="first"><a href="/">home</a></li>
            <li><a href="/archive/">archive</a></li>
            <li><a href="/tags/">tags</a></li>
            <li class="last"><a href="/about/">about me</a></li>
        </ul>

        <div class="clearboth"></div>

        <section id="content">

    <h1 class="title">import tensorflow에서 벗어나기</h1>

        <div class="date">
            <p>March 15, 2019</p>
        </div>

    <div class="clearboth article-content">
        <p>Sutton 교수님께서 70년간 AI 연구자들이 반복한 실수와 그로부터 우리가 배워야 하는 것에 대한 글 <a class="reference external" href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">&lt;The Bitter Lesson&gt;</a> 을 공유했다. 글을 관통하는 메세지는 체스, 바둑 같은 역사적 사례에서 볼 수 있듯이 인공지능의 혁신은 언제나 computation에 있었다는 것. General하고 scalable한 알고리즘만이 생존하고 세상을 바꾼다는 것.</p>
<p>GPU 1개로 논문을 구현할 수 있었던 1, 2년 전과 달리 지금은 DGX 하나로도 SOTA를 찍기 어려워졌다. 돈이 없으면 논문 하나도 제대로 구현 못 하는데, DGX가 있더라도 full로 쓰는 법을 모르면 빛 좋은 개살구일 뿐이다. 하지만 딥러닝의 기초, 퍼셉트론, LSTM 정도의 튜토리얼이 수도 없이 재생산되고 +0.3% SOTA 같은 쓸데없는 정보들이 공유되는 환경에서 optimization이나 low-level 엔지니어링에 대한 필요성을 느끼거나 정보를 얻기란 굉장히 어렵다.</p>
<p>나를 예를 들면, 적당히 모델을 학습시킬 때 GPU-utilization이 90% 이상을 찍고 있지 않다면 어딘가에 bottleneck이 있고, 그걸 프로파일러로 찾을 수 있다는 것, 그래프를 cpu에 먼저 넣고 컴파일해서 gpu에 넣으면 OOM을 피할 수 있다거나, <a class="reference external" href="https://github.com/tensorflow/tensorflow/blob/32edfdd8e4d24db2a3789c85227f1887e4faca95/tensorflow/python/framework/function.py#L45">tf.Defun</a> 같은 걸 언제 왜 써야 하는지, <a class="reference external" href="https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/">fp16</a> 과 <a class="reference external" href="https://openai.com/blog/block-sparse-gpu-kernels/">sparsity</a> 가 왜 중요한지, <a class="reference external" href="https://arxiv.org/abs/1412.6980">Adam</a> 과 <a class="reference external" href="https://arxiv.org/abs/1804.04235">adafactor</a> 가 어떻게 다른지, tf.cast 같은 함수가 얼마나 비효율적인지, <a class="reference external" href="https://www.tensorflow.org/api_docs/python/tf/custom_gradient">tf.custom_gradient</a> 와 <a class="reference external" href="https://www.tensorflow.org/guide/extend/op">custom op</a> 으로 어떻게 그런 비효율을 없앨 수 있는지 따위를 알아야 한다는 걸 몰랐다.</p>
<p>만약 세상의 &quot;진짜&quot; 문제를 “직접” 풀고 싶지만 논문을 읽고 구현하는데 매너리즘에 빠져다면, import tensorflow에서 벗어나 compute에 대해 고민해보는게 도움이 될 것 같다. <a class="reference external" href="https://www.nvidia.com/en-us/data-center/tensorcore/">Tensor Core</a> 와 같은 하드웨어에 대한 이해부터 MPI, <a class="reference external" href="https://docs.nvidia.com/deeplearning/sdk/nccl-developer-guide/docs/index.html">NCCL</a>, <a class="reference external" href="https://docs.nvidia.com/deeplearning/sdk/mixed-precision-training/">fp16</a> 과 <a class="reference external" href="https://www.tensorflow.org/xla">sparsity &lt;https://openai.com/blog/block-sparse-gpu-kernels/&gt;`__와 `TensorFlow XLA</a>, <a class="reference external" href="https://github.com/tensorflow/mesh/">Mesh TensorFlow</a>, <a class="reference external" href="https://github.com/horovod/horovod">Horovod</a> 등으로 Data/Model parallelization를 하는 것, Adafactor, <a class="reference external" href="https://openai.com/blog/block-sparse-gpu-kernels/">Blocksparse</a>, <a class="reference external" href="https://github.com/openai/gradient-checkpointing">Gradient recompute</a>, <a class="reference external" href="http://docs.nvidia.com/cuda/profiler-users-guide/index.html">nvprof</a> 따위로 memory optimization과 Compute/Network/Pipeline bandwidth에서 bottleneck을 없애는 것. 그리고 <a class="reference external" href="https://arxiv.org/abs/1901.02860">Transformer-xl</a>, <a class="reference external" href="https://arxiv.org/abs/1809.11096">BigGAN</a>, <a class="reference external" href="https://openai.com/blog/better-language-models/">GPT-2</a> 와 같은 논문들 뒤에 보이지 않는 엔지니어링을 생각하고, 찾아보고, 구현하는 것.</p>
<p><a class="reference external" href="https://openai.com/blog/better-language-models/">GPT-2</a> 가 보여주었듯이 scalable한 모델을 만들고 다룰 수 있느냐 없느냐에 따라 풀 수 있는 문제의 범위와 그 결과가 크게 바뀐다. 세상이 바뀌듯 우리도 변해야 한다.</p>
<ul class="simple">
<li>The Bitter Lesson: <a class="reference external" href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html">http://www.incompleteideas.net/IncIdeas/BitterLesson.html</a></li>
<li>Mesh TensorFlow: <a class="reference external" href="https://www.youtube.com/watch?v=HgGyWS40g-g">https://www.youtube.com/watch?v=HgGyWS40g-g</a></li>
<li>Horovod: <a class="reference external" href="https://github.com/horovod/horovod">https://github.com/horovod/horovod</a></li>
<li>TF custom op: <a class="reference external" href="https://www.tensorflow.org/guide/extend/op">https://www.tensorflow.org/guide/extend/op</a></li>
<li>TF performance: <a class="reference external" href="https://www.tensorflow.org/guide/performance/overview">https://www.tensorflow.org/guide/performance/overview</a></li>
<li>Tensorpack: <a class="reference external" href="https://github.com/tensorpack/benchmarks/tree/master/DCGAN">https://github.com/tensorpack/benchmarks/tree/master/DCGAN</a></li>
<li>Tensor cores: <a class="reference external" href="https://stackoverflow.com/questions/47335027">https://stackoverflow.com/questions/47335027</a></li>
<li>Parallel and Distributed Deep Learning: <a class="reference external" href="https://www.youtube.com/watch?v=xtxxLWZznBI">https://www.youtube.com/watch?v=xtxxLWZznBI</a></li>
<li>Blocksparse: <a class="reference external" href="https://openai.com/blog/block-sparse-gpu-kernels/">https://openai.com/blog/block-sparse-gpu-kernels/</a></li>
<li>Gradient checkpoint: <a class="reference external" href="https://github.com/openai/gradient-checkpointing">https://github.com/openai/gradient-checkpointing</a></li>
</ul>

    </div>

        <div class="tags">
            <p>태그 : 
<a href="https://carpedm20.github.io/tags/ai/">ai</a></p>
        </div>

<div id="disqus_thread"></div>
<script type="text/javascript">
    /* * * CONFIGURATION VARIABLES: EDIT BEFORE PASTING INTO YOUR WEBPAGE * * */
    var disqus_shortname = "carpedm20";
    var disqus_title = "import tensorflow에서 벗어나기";
    var disqus_url = "https://carpedm20.github.io/2019/tensorflow/";

    /* * * DON'T EDIT BELOW THIS LINE * * */
    (function() {
        var dsq = document.createElement('script'); dsq.type = 'text/javascript'; dsq.async = true;
        dsq.src = '//' + disqus_shortname + '.disqus.com/embed.js';
        (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="http://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="http://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>

        </section>
    </div>

    <div id="footer">
      <p>Powered by <a href="http://blog.getpelican.com/">Pelican</a></p>
    </div>

    <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-60954038-1', 'auto');
      ga('send', 'pageview');

    </script>
    <script src="//code.jquery.com/jquery-1.11.0.min.js"></script>
    <script src="../theme/js/mfb.js"></script>
    <script src="../theme/js/modernizr.touch.js"></script>
    <script src="../theme/js/script.js"></script>


</body>

</html>